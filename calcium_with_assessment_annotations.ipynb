{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a92271c",
   "metadata": {},
   "source": [
    "# Automating the interpretation of calcium assay data \n",
    "\n",
    "Annotations specific to this run through for assessment are written in **. They are not included in the usual code.\n",
    "\n",
    "## Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3df130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the packages we'll be using:\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2b33f",
   "metadata": {},
   "source": [
    "## Reading in data\n",
    "I found that I could only import data from my github if i called it in the raw format, here i've done this automatically so that you can copy the URL directly from the github website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ab0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/U1711/calcium_project/blob/main/Fucosidosis%20A%2013032018.csv' #<--- insert URL here\n",
    "\n",
    "# * I have already included a test document at the specified URL*\n",
    "\n",
    "print(\"The URL is:\", url)\n",
    "\n",
    "\n",
    "#Data doesn't seem to import unless it is in 'raw' format\n",
    "raw_url = url.replace(\"blob\", \"raw\")\n",
    "\n",
    "print(\"\\nOur converted raw URL is:\", raw_url)\n",
    "\n",
    "\n",
    "# Reading in our data\n",
    "test_dataset = pd.read_csv(raw_url)\n",
    "\n",
    "print(\"\\nThis is the whole dataset below:\\n\\n\", test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ce354",
   "metadata": {},
   "source": [
    "The amount of columns here looks a bit messy, only some are of interest... \n",
    "\n",
    "## Tidying up test_dataset\n",
    "\n",
    "The columns of interest are Time (sec) and the R[i] R1 columns.\n",
    "The first R refers to the Region, in this case individual cells.\n",
    "The second R1 is the ratio between W1 and W2, this is what we're interested in and as the ratio has already been calculated for us we no longer need W1 and W2.\n",
    "\n",
    "### Deleting unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac382c40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identifying and deleting R[i] W1 Avg columns\n",
    "Ri_W1_Avg_columns = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    column_name = 'R' + str(i) + ' W1 Avg'\n",
    "    if column_name in test_dataset.columns:\n",
    "        Ri_W1_Avg_columns.append(column_name)\n",
    "\n",
    "if len(Ri_W1_Avg_columns) > 0:\n",
    "    test_dataset = test_dataset.drop(columns=Ri_W1_Avg_columns)\n",
    "\n",
    "    \n",
    "# Identifying and deleting R[i] W2 Avg columns\n",
    "Ri_W2_Avg_columns = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    column_name = 'R' + str(i) + ' W2 Avg'\n",
    "    if column_name in test_dataset.columns:\n",
    "        Ri_W2_Avg_columns.append(column_name)\n",
    "\n",
    "if len(Ri_W2_Avg_columns) > 0:\n",
    "    test_dataset = test_dataset.drop(columns=Ri_W2_Avg_columns)\n",
    "\n",
    "    \n",
    "# Deleting columns where all the values are NaN\n",
    "test_dataset = test_dataset.dropna(axis=1, how=\"all\")\n",
    "\n",
    "\n",
    "# Deleting columns that contain only 0 and NaN values\n",
    "columns = test_dataset.columns[test_dataset.isin([0, pd.np.nan]).all() & test_dataset.notnull().any(axis=0)]\n",
    "\n",
    "test_dataset = test_dataset.drop(columns=columns)\n",
    "\n",
    "\n",
    "# Deleting unnamed columns\n",
    "test_dataset = test_dataset.drop(columns=[col for col in test_dataset.columns if \"Unnamed:\" in col])\n",
    "\n",
    "\n",
    "print(\" This is the test dataset without: R[i] W1 or W2 Avg columns, NaN columns, blank columns or unnamed columns:\\n\\n\", test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327494da",
   "metadata": {},
   "source": [
    "### Naming our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the 'Time (sec)' column the name 'time'\n",
    "\n",
    "time = test_dataset[\"Time (sec)\"]\n",
    "\n",
    "\n",
    "# Assigning the R[i] R1 columns the name calcium_r[i]\n",
    "\n",
    "for i in range(1, 51):\n",
    "    try:\n",
    "        exec(f'calcium_r{i} = test_dataset[\"R{i} R1\"].values')\n",
    "    except KeyError:\n",
    "\n",
    "        continue\n",
    "\n",
    "\n",
    "print(\"Our time dataset looks like this:\\n\\n\", time, \"\\n\\n\\n\\n And an example of our calcium_r[i] (9) dataset looks like this:\\n\\n\", calcium_r9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f85ce6",
   "metadata": {},
   "source": [
    "## Visualising all of our calcium_r[i] data against time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting 25 rows of 2 columns (enough for up to 50 calcium_r[i])\n",
    "nrows = math.ceil(50 / 2)\n",
    "ncols = 2\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(10, nrows*5)) # Creating figure/subplots\n",
    "\n",
    "axs = axs.flatten() # Flattening the subplot array to make it easier to iterate over\n",
    "\n",
    "# Looping through the variables to plot each one\n",
    "for i, ax in enumerate(axs):\n",
    "    calcium_r = \"calcium_r\" + str(i+1)\n",
    "    if calcium_r in locals():\n",
    "        ax.plot(time, locals()[calcium_r], 'b.')\n",
    "        ax.set_title(\"Calcium {}/Time\".format(i+1))\n",
    "        ax.set_ylabel(\"Calcium {}\".format(i+1))\n",
    "        ax.set_xlabel(\"Time (sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305b851",
   "metadata": {},
   "source": [
    "The data seems to consist of swift incline (the action of a drug) which comes to a peak followed by a small lag period and a swift decline. This decline then plateaus to a trough, and finally the data tails off and rises again.\n",
    "I am interested in identifying the steep rate of decline after the lag phase but before the decline begins to plateau - this should be a fairly consistent measure of how quickly calcium levels return to normal.\n",
    "\n",
    "## Identifying the rate at which calcium levels return to normal following the peak\n",
    "\n",
    "This code was designed to call a range of datasets with up to 50 regions/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cdb76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining calcium_r[i] and time into a list of tuples\n",
    "for i in range(1, 51):\n",
    "    try:\n",
    "        globals()['time_tuples' + str(i)] = list(zip(time, locals()['calcium_r' + str(i)]))\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Calculating the gradient between the tuples\n",
    "for i in range(1, 51):\n",
    "    try:\n",
    "        gradients = []\n",
    "        for j in range(len(globals()['time_tuples' + str(i)])-1):\n",
    "            gradient = (globals()['time_tuples' + str(i)][j+1][1] - globals()['time_tuples' + str(i)][j][1]) / (globals()['time_tuples' + str(i)][j+1][0] - globals()['time_tuples' + str(i)][j][0])\n",
    "            gradients.append(gradient)\n",
    "        globals()['gradients' + str(i)] = gradients\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Defining a function to find the longest straight(ish) declining line (this should be the line of interest) based on a\n",
    "    # tolerance of 'straightness'.\n",
    "def calculate_average_gradient(times, values, tolerance):\n",
    "  time_tuples = list(zip(times, values))\n",
    "  gradients = []\n",
    "  for i in range(len(time_tuples)-1):\n",
    "    gradient = (time_tuples[i+1][1] - time_tuples[i][1]) / (time_tuples[i+1][0] - time_tuples[i][0])\n",
    "    gradients.append(gradient)\n",
    "  max_length = 0\n",
    "  start_index = 0\n",
    "  end_index = 0\n",
    "  previous_gradient = gradients[0]\n",
    "  for i in range(len(time_tuples)-1):\n",
    "    length = 0\n",
    "    for j in range(i, len(time_tuples)-1):\n",
    "      average_gradient = (time_tuples[j+1][1] - time_tuples[i][1]) / (time_tuples[j+1][0] - time_tuples[i][0])\n",
    "      percentage_change = (gradients[j] - average_gradient) / average_gradient\n",
    "      if abs(percentage_change) < tolerance and average_gradient < 0:\n",
    "        length += 1\n",
    "        previous_gradient = average_gradient\n",
    "      else:\n",
    "        break\n",
    "    if length > max_length:\n",
    "      max_length = length\n",
    "      start_index = i\n",
    "      end_index = i+length\n",
    "  times1, values1 = zip(*time_tuples[start_index:end_index+1])\n",
    "  average_gradient = (values1[-1] - values1[0]) / (times1[-1] - times1[0])\n",
    "  return average_gradient, start_index, end_index\n",
    "\n",
    "\n",
    "# Setting the tolerances for all calcium_r[i] to a default 0.3 - seems to work in the majority of cases\n",
    "for i in range(1, 51):\n",
    "    if f'calcium_r{i}' in globals():\n",
    "        exec(f'tolerance{i} = 0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c16a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the function on all calcium_r[i] to find the line of interest in each \n",
    "for i in range(1, 51):\n",
    "  try:\n",
    "    calcium_r_values = globals()[\"calcium_r\"+str(i)]  # Get the calcium_r values for the current iteration\n",
    "    tolerance = globals()[\"tolerance\"+str(i)]  # Get the tolerance value for the current iteration\n",
    "    average_gradient, start_index, end_index = calculate_average_gradient(time, calcium_r_values, tolerance)\n",
    "    globals()[\"average_gradient\"+str(i)] = average_gradient\n",
    "    globals()[\"start_index\"+str(i)] = start_index\n",
    "    globals()[\"end_index\"+str(i)] = end_index\n",
    "  except KeyError:\n",
    "    # Skip the iteration if the variable is not defined\n",
    "    continue\n",
    "\n",
    "# Extracting the start and end index for the lines - this will be useful in plotting them later! \n",
    "for i in range(1, 51):\n",
    "  try:\n",
    "    start_index = globals()[\"start_index\"+str(i)]  # Get the start index for the current iteration\n",
    "    end_index = globals()[\"end_index\"+str(i)]  # Get the end index for the current iteration\n",
    "    time_tuples_values = globals()[\"time_tuples\"+str(i)]  # Get the time_tuples values for the current iteration\n",
    "    times, values = zip(*time_tuples_values[start_index:end_index+1])\n",
    "    globals()[\"times\"+str(i)] = times\n",
    "    globals()[\"values\"+str(i)] = values\n",
    "  except KeyError:\n",
    "    # Skip the iteration if the variable is not defined\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff2f6b8",
   "metadata": {},
   "source": [
    "## Plotting all of our lines on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff51bb9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting the number of rows and columns for the subplots\n",
    "nrows = math.ceil(50 / 2)\n",
    "ncols = 2\n",
    "\n",
    "# Creating the figure and subplots\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(10, nrows*5))\n",
    "\n",
    "# Flattening the subplot array to make it easier to iterate over\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Looping through the variables to plot each one\n",
    "for i, ax in enumerate(axs):\n",
    "    calcium_r = \"calcium_r\" + str(i+1)\n",
    "    values = \"values\" + str(i+1)\n",
    "    times = \"times\" + str(i+1)\n",
    "    if calcium_r in locals() and values in locals() and times in locals():\n",
    "        ax.plot(time, locals()[calcium_r], 'b.')\n",
    "        ax.plot(locals()[times], locals()[values], 'r-')\n",
    "        ax.set_title(\"R{} calcium over time + fitted line (red)\".format(i+1))\n",
    "        ax.set_ylabel(\"Calcium level\".format(i+1))\n",
    "        ax.set_xlabel(\"Time (sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f79633",
   "metadata": {},
   "source": [
    "## Making any reqired changes\n",
    "\n",
    "### Refining tolerances\n",
    "\n",
    "Once you've visualised the lines on the plots it's possible to edit the tolerance for each plot to try and improve the fit - this should only be required for a limited number of the plots as the default value works quite well! Increasing the tolerance should allow the line to get larger and work it's way through messier data, if the line is overstretched across the lag region or where the line begins to plateau it may be suitable o decrease the tolerance to improve the fit of the line.\n",
    "\n",
    "Change the tolerance levels of specific calcium_r[i] by using the following format below:\n",
    "\n",
    "(Do this as many times as required.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tolerance[i] = 0.4\n",
    "\n",
    "# *As an example - above the line fitted to calcium_r13 seems to include the lag period which is visibly\n",
    "        # skewing the gradient.*\n",
    "\n",
    "tolerance13 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d8630c",
   "metadata": {},
   "source": [
    "Now go back up and run the cell titled '# Running the function...'\n",
    "\n",
    "Run that and the next cell to re-plot the data and check your fit.\n",
    "\n",
    "Either make further adjustments or continue on to calculate the overall average gradient for this data sheet.\n",
    "   \n",
    "*The calcium_r13 line is looking better! Time to continue... (no need to use our last resort!)*\n",
    "\n",
    "### Last resort\n",
    "\n",
    "As a last resort, if a line cannot be fitted to the graph it is possible to remove that cell by:\n",
    "\n",
    "Removing the # below and replace [i] by the calcium_r[i] of interest.\n",
    "        \n",
    "This may reduce the acuracy of the overall average gradient for this cell type calculated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794cdbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del average_gradient[i]\n",
    "\n",
    "# *No need to do this as all our lines are plotted quite nicely!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a07345",
   "metadata": {},
   "source": [
    "## Calculating the overall average gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b29533",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_decline_gradients = {} # Creating a dictionary for our average_decline_gradients for each calcium_r[i]\n",
    "\n",
    "# Looping through the variables and adding their average decline gradients to the dictionary\n",
    "for i in range(1, 51):\n",
    "    gradient = \"average_gradient\" + str(i)\n",
    "    if gradient not in locals():\n",
    "        continue\n",
    "    average_decline_gradients[i] = locals()[gradient]\n",
    "\n",
    "\n",
    "# Defining a function to take an average of all the numbers in a dictionary.   \n",
    "def average_gradient(dictionary):\n",
    "    total_sum = 0\n",
    "    num_elements = 0\n",
    "    for key, value in dictionary.items():\n",
    "        total_sum += value\n",
    "        num_elements += 1\n",
    "    return total_sum / num_elements, num_elements\n",
    "\n",
    "# Using this function to calculate the overall average gradient from the average_decline_gradients dictionary.\n",
    "overall_average_gradient, num_elements = average_gradient(average_decline_gradients)\n",
    "\n",
    "print(\"The overall average gradient of calcium recovery of these\", num_elements, \"cells is:\", overall_average_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a5878e",
   "metadata": {},
   "source": [
    "# Success!\n",
    "### The avereage gradient can now be compared with other disease-states and analysed further!\n",
    "*Thank you for looking through my code!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7025468f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
